{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "str_tab = 8\n",
    "minIP = 0\n",
    "url = 'https://www.fangraphs.com/leaders.aspx?pos=all&stats=pit&lg=all&qual={0}&type={1}&season=2022&month=0&season1=2022&ind=0&team=&rost=&age=&filter=&players=&startdate=&enddate=&page=1_30'.format(minIP, str_tab)\n",
    "page = requests.get(url)\n",
    "soup = BeautifulSoup(page.text, 'lxml')\n",
    "\n",
    "\n",
    "\n",
    "table1 = soup.find('table', id='LeaderBoard1_dg1_ctl00')\n",
    "headers = []\n",
    "div_pages = soup.find(\"div\", {\"class\": \"rgWrap rgInfoPart\"})\n",
    "texts = [r.text.strip() for r in div_pages]\n",
    "pages = int(texts[3])\n",
    "for i in table1.find_all('th'):\n",
    "    title = i.text\n",
    "    headers.append(title)        \n",
    "mydataComplete = pd.DataFrame(columns = headers)\n",
    "\n",
    "for page_number in range(0, pages):\n",
    "    page_number_page = page_number+1\n",
    "    url = 'https://www.fangraphs.com/leaders.aspx?pos=all&stats=pit&lg=all&qual={0}&type={1}&season=2022&month=0&season1=2022&ind=0&team=&rost=&age=&filter=&players=&startdate=&enddate=&page={2}_30'.format(minIP, str_tab, page_number_page)\n",
    "    \n",
    "    # Create object page\n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.text, 'lxml')\n",
    "    table1 = soup.find('table', id='LeaderBoard1_dg1_ctl00')\n",
    "    headers = []\n",
    "    for i in table1.find_all('th'):\n",
    "        title = i.text\n",
    "        headers.append(title)            \n",
    "    mydata = pd.DataFrame(columns = headers)\n",
    "    \n",
    "    idx = 0\n",
    "    for j in table1.find_all('tr')[1:]:\n",
    "        row_data = j.find_all('td')\n",
    "        row = [i.text for i in row_data]\n",
    "        length = len(mydata)\n",
    "        if idx<=1:\n",
    "            idx=idx+1\n",
    "            continue\n",
    "        mydata.loc[length] = row\n",
    "    frames = [mydataComplete, mydata]\n",
    "    df_pages = pd.concat(frames)\n",
    "    mydataComplete = df_pages \n",
    "\n",
    "mydataComplete['IP'] = mydataComplete['IP'].astype(float)\n",
    "picherts_type = mydataComplete.nlargest(156, 'IP')\n",
    "threshold_ip_star = picherts_type['IP'].min()\n",
    "mydataComplete.loc[mydataComplete['IP']>=threshold_ip_star, 'Type']= 'Starter'\n",
    "mydataComplete.loc[mydataComplete['IP']<threshold_ip_star, 'Type']= 'Reliever'\n",
    "picherts_type = mydataComplete[['Name','Team', 'Type']]\n",
    "picherts_type.to_csv('data/picherts_type.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c4f92193806e2908606a5f23edd55a5282f2f433b73b1c504507f9256ed9f0b4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
