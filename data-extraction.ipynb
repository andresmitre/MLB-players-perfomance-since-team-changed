{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_dictionary = pd.read_csv(\"tab_dictionary.csv\")\n",
    "month_dictionary = pd.read_csv(\"tab_month.csv\")\n",
    "\n",
    "dict = pd.Series(table_dictionary.table_name.values,\n",
    "                 index=table_dictionary.index).to_dict()\n",
    "\n",
    "dict_month = pd.Series(month_dictionary.month.values,\n",
    "                 index=month_dictionary.index).to_dict()\n",
    "\n",
    "generic_url = 'https://www.fangraphs.com/leaders.aspx?pos=all&stats=pit&lg=all&qual=y&type=8&season=2022&month=0&season1=2022&ind=0'\n",
    "page = requests.get(generic_url)\n",
    "soup = BeautifulSoup(page.text, 'lxml')\n",
    "\n",
    "for tab in range (1,24):\n",
    "    str_tab = str(tab)\n",
    "    div_pages = soup.find(\"div\", {\"class\": \"rgWrap rgInfoPart\"})\n",
    "    texts = [r.text.strip() for r in div_pages]\n",
    "    pages = int(texts[3])\n",
    "    # dictionary from 0-5\n",
    "    for month in range(0,6):\n",
    "        month_number_page = month+4\n",
    "        for page_number in range(0, pages):\n",
    "            page_number_page = page_number+1\n",
    "            url = 'https://www.fangraphs.com/leaders.aspx?pos=all&stats=pit&lg=all&qual=y&type={0}&season=2022&month={1}&season1=2022&ind=0&page={2}_30'.format(str_tab, month_number_page, page_number_page)\n",
    "            \n",
    "            # Create object page\n",
    "            page = requests.get(url)\n",
    "\n",
    "            # parser-lxml = Change html to Python friendly format\n",
    "            # Obtain page's information\n",
    "            soup = BeautifulSoup(page.text, 'lxml')\n",
    "\n",
    "            table1 = soup.find('table', id='LeaderBoard1_dg1_ctl00')\n",
    "            headers = []\n",
    "            for i in table1.find_all('th'):\n",
    "                title = i.text\n",
    "                headers.append(title)\n",
    "                \n",
    "            mydata = pd.DataFrame(columns = headers)\n",
    "            idx = 0\n",
    "            for j in table1.find_all('tr')[1:]:\n",
    "                row_data = j.find_all('td')\n",
    "                row = [i.text for i in row_data]\n",
    "                length = len(mydata)\n",
    "                if idx<=1:\n",
    "                    idx=idx+1\n",
    "                    continue\n",
    "                mydata.loc[length] = row\n",
    "            mydata['MonthSeason'] = month+1\n",
    "            mydata['MonthYear'] = month_number_page\n",
    "            mydata.to_csv('data/{0}/{1}_Page_{2}.csv'.format(dict.get(tab), dict_month.get(month), page_number), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c4f92193806e2908606a5f23edd55a5282f2f433b73b1c504507f9256ed9f0b4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
